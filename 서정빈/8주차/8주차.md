# 쿠버네티스 체험하기

백기선의 쿠버네티스 시작하기를 통하여 한 번 진행해보았다.

![1. ks8 start.png](1.%20ks8%20start.png)

minikube를 현재 터미널에서 다운 받았다. 한글이 지원되다니.. 신기했다

![2. download minikube.png](2.%20download%20minikube.png)

위에 떠있는 control plane(https://127.0.0.1:55280)에 들어가보면 아래의 정보가 뜬다.
403이 뜬 걸 보니 오류가 뜬 거 같다.

![3. 403 error.png](3.%20403%20error.png)

다시 해보니까, 백기선씨 유튜브랑 조금 다르게..? 진행 된 거 같다. 동일한 코드를 쳐도 다른 값이 나온다.

![4. make deployment, wrong.png](4.%20make%20deployment%2C%20wrong.png)

pod가 생성? 되는 모습을 보인다.
—> 챗지피티한테 물어보니 아래의 답을 해주었다.

`kubectl run` 명령어는 기본적으로 Deployment가 아닌 Pod를 생성합니다. 원래는 `kubectl run` 명령어가 Deployment를 생성하는 데 사용되었으나, Kubernetes 버전 1.18부터 이 명령어의 기본 동작이 변경되었습니다. 이제 `kubectl run` 명령어는 기본적으로 단일 Pod를 생성합니다.

Deployment를 생성하려면 `kubectl create deployment` 명령어를 사용하거나, `kubectl run` 명령어에 추가적인 옵션을 사용해야 합니다.

코드를 아래와 같이 수정했다.

kubectl create deployment kubernetes-bootcamps --image=[gcr.io/google-samples/kubernetes-bootcamp:v1](http://gcr.io/google-samples/kubernetes-bootcamp:v1)

![5. make deployment, right.png](5.%20make%20deployment%2C%20right.png)

백기선씨처럼 잘 되는 모습이다.
추가적으로 다른 터미널에서 “kubectl proxy”를 통해서 서버를 열어줘야 아래의 버전 확인에서 오류가 발생하지 않는다.

![6. kubectl proxy.png](6.%20kubectl%20proxy.png)

![7. version check.png](7.%20version%20check.png)

403 오류 났던 부분도 잘 해결된 모습이다.
이렇게 앱 배포가 가능한 것 같다.

아래는 쿠버네티스의 전체적인 구조이다.

![8. k8s structure.png](8.%20k8s%20structure.png)

클러스터 : 가장 큰 단위, 가상 서버들이 속한 클라우드
→ 마스터노드 + 워커 노드를 합친 것

노드 : 클러스터 내 가상 서버, 컴퓨팅 엔진 단위이며 마스터/워커 노드로 분리

- 마스터 노드: 쿠버네티스 컨트롤 플레인을 담당
- 워커 노드 : 배포하고자 하는 어플리케이션의 실제 실행 수행

→ 마스터 노드가 죽으면 클러스터 관리 노드 X, 일반적으로 3개 정도 띄워둔다고 하며 워커 노드도 여러 개 구성 가능

포드 : 쿠버네티스에서 생성하고 관리할 수 있는 배포 가능한 가장 작은 컴퓨팅 단위, 하나 이상의 컨테이너 그룹

- 컨테이너는 애플리케이션 → 이는 완전한 애플리케이션의 일부 기능 / 완전한 것 그 자체 일 수 있음
- 만약 일부 기능이라면?
  - 여러 개의 컨테이너들이 모여 하나의 완전한 어플리케이션을 구성
  - 이때에는 여러 컨테이너가 하나의 파드 → 이 파드는 완전한 어플리케이션
- 만약 컨테이너 1개가 완전한 어플리케이션 기능이라면? → 이는 하나의 파드를 구성 가능
- 파드에 정의된 여러 개의 컨테이너는 하나의 완전한 애플리케이션으로서 동작

구조는 클러스터 → 노드 → 파드 → 컨테이너로 나눌 수 있다.

kubectl descibe pods를 이용하면 각 포드의 정보를 얻을 수 있다.

![9. kubectl descibe pods.png](9.%20kubectl%20descibe%20pods.png)

양이 많아서 일부만 캡처를 진행했다.

백기선씨의 유튜브를 그대로 보고 따라해도, 조금 다른 결과가 나오는 건 왜인지 모르겠다.
Hello Kubernetes bootcamp!가 뜨질 않는다..

![10. check proxy.png](10.%20check%20proxy.png)

API를 반환하는 코드를 작성했는데, 반환하지를 않는다.

kubectl logs $POD_NAME을 이용하면 로그도 볼 수 있다.

![11. log check.png](11.%20log%20check.png)

kubectl exec -ti $POD_NAME bash를 이용하면 컨테이너에 접속할 수 있다.

![12. exec bash.png](12.%20exec%20bash.png)

root 사용자로 바뀐 것을 볼 수 있다. ls 명령어 사용시 컨테이너 안의 폴더도 볼 수 있다.

![13. bash ls.png](13.%20bash%20ls.png)

여기서 cat server.js 명령어를 이용하니 원래 서버 API를 작동하면 뜨는 js 코드가 적혀있었다.

![14. cat server.js.png](14.%20cat%20server.js.png)

## 서비스

네트워크 서비스로 노출하는 추상화 방법을 의미 → Pod를 논리적으로 구분하여 접근하는 것
서비스에서는 Label Selector를 사용하여 Pod를 정의

- Cluster IP : 기본 서비스타입, 쿠버네티스 클러스터 내부에서 사용 가능, 클러스터 내부의 Node나 Pod에서 이 ClusterIP를 이용하여 서비스에 연결된 Pod와 통신(IGW 느낌?)
  - 외부 직접 접근 불가능하며, 클러스터 내부에서 다른 Pod들이 특정 서비스에 접근해야하는 경우 사용
- External Name : 서비스를 externalName의 값이랑 매치하여 사용, 클러스터 내부 → 외부 접근시 사용
  - 외부 DNS 이름을 서비스로 매핑함
- NodePort : 클러스터의 각 노드에서 지정된 포트를 외부에 노출함, 노드의 IP주소와 지정 포트를 이용해 외부에 서비스를 진행
  - 외부 클라이언트가 직접 클러스터 노드에 접근하는 간단한 방식으로 사용
- Load Balancer : Pod를 클라우드에서 제공해주는 Load Balancer와 연결, 그 Load Balancer의 IP를 이용
  - 클라우드 환경에서 서비스 외부 접근을 용이하고자 할 때 사용

이러한 서비스 통신을 가능하게 하는 것이 kube-proxy, 각 Node의 쿠버네티스 API에 정의된 서비스를 반영하며 단순한 TCP, UDP, SCTP를 이용하고, 쿠버네티스 Service에 클라이언트가 연결할 수 있는 역할

## Kube-Proxy

- Userspace mode

![15. Userspace mode.png](15.%20Userspace%20mode.png)

→ 쿠버네티스에서 각 서비스는 Node에서 랜덤하게 Port를 선택하여 오픈, 오픈된 Port로 redirect 진행
이 과정에서 kube-proxy는 어떤 Pod로 연결할지 결정, 요즘은 성능상 제한으로 잘 안 씀

- iptables mode

![16. iptables mode.png](16.%20iptables%20mode.png)

→ 각 서비스에 대해 IP 주소와 포트에 대한 규칙을 “iptables”로 설정, 서비스로 들어오는 트래픽이 해당 규칙에 따라 적절한 Pod로 연결, 사용이 간편하고 성능이 개선
하지만 복잡한 클러스터 구조를 사용 할 때 성능 이슈가 발생할 수 있음

- IPVS(IP Virtual Server) mode

![17. IPVS mode.png](17.%20IPVS%20mode.png)

kube-proxy가 IPVS를 사용하여 서비스와 Pod 간의 트래픽을 처리, 더 나은 확장성을 제공

- iptables mode의 단점을 보완
  - 확장성 : IPVS는 수천 개의 서비스와 Pod를 처리, 무제한 확장 가능
  - 성능 : IPVS는 ‘iptables’에 비해 낮은 대기 시간 및 높은 처리량을 가짐
  - 연결 관리 : IPVS는 각 연결 상태를 모니터링, 문제가 있는 연결을 자동 재시도(헬스 체크)

![18. ClusterIP service.png](18.%20ClusterIP%20service.png)

현재는 ClusterIP로 서비스가 돌아가고 있는 것을 볼 수 있다.

만들어둔 deployments를 아래의 명령어를 통해 Nodeport 형식으로 서비스를 하게 했다.
kubectl expose deployment/{deployment_name} —type=”{service_name}” —port {port_number}

![19. Nodeport service.png](19.%20Nodeport%20service.png)

이 과정에서 열리는 외부로 보이는 포트(30443)는 랜덤으로 배정되는 것 같다.

## Scaling & Rolling update

deployment를 스케일 아웃시 신규 pod가 생성, 가용할 자원이 있는 노드에 스케줄한다.
k8s에서는 오토 스케일링도 지원하고, 0까지도 가능하다고 한다.(끄는 것과 다를 게 없다)

scale 명령어를 통하여 레플리카를 4개로 늘려봤다.
kubectl scale deployments/kubernetes-bootcamps —replica={원하는 레플리카 개수}

![20. Scaling.png](20.%20Scaling.png)

모든 요소가 4개로 늘어난 것을 볼 수 있다!

wide라는 명령어를 사용하니 가지고 있는 현재 구동되고 있는 pod 4개가 잘 출력된다.

![21. get pods scale.png](21.%20get%20pods%20scale.png)

동일하게 줄일수도 다. 2개로 줄여봤다.

![22. Scale out.png](22.%20Scale%20out.png)

롤링 업데이트도 가능하다고 한다.
현재 가지고 있는 4개의 pod에 대해 롤링 업데이트를 진행했다.
유튜브보다 조금 늦게 진행했더니, 이미 업데이트가 다 완료되었다(Age의 변화로 체크 완료)
kubectl set image deployment/{deployments_name} {container_name}={image}:{version}

![23. Rolling update.png](23.%20Rolling%20update.png)

업데이트의 성공여부도 확인할 수 있었다.
kubectl rollout status deployments/{deployments_name}

![24. rollout status.png](24.%20rollout%20status.png)

undo 명령어를 이용한다면, 롤백도 진행할 수 있다.
아마 버전도 선택할 수 있지 않을까 싶다. 난 v2 → v1으로의 롤백을 진행했다.
kubectl rollout undo deployments/{deployments_name}

![25. rollout undo.png](25.%20rollout%20undo.png)










